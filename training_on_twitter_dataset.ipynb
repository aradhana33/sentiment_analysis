{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FBHTP89VziB4"
      },
      "outputs": [],
      "source": [
        "# SVM\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Download NLTK resources\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Load data from CSV\n",
        "data = pd.read_csv('/content/sample_data/dataset_tweet_sentiment.csv')\n",
        "\n",
        "# Data preprocessing\n",
        "stop_words = set(stopwords.words('english'))\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "def preprocess_text(text):\n",
        "    words = nltk.word_tokenize(text)\n",
        "    words = [stemmer.stem(word) for word in words if word.isalnum()]\n",
        "    words = [word.lower() for word in words if word.lower() not in stop_words]\n",
        "    return ' '.join(words)\n",
        "\n",
        "data['text'] = data['text'].apply(preprocess_text)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(data['text'], data['sentiment'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Label encoding for sentiment labels\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(y_train)\n",
        "y_test_encoded = label_encoder.transform(y_test)\n",
        "\n",
        "# Create a pipeline with TF-IDF vectorizer and SVM classifier\n",
        "svm_model = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer()),\n",
        "    ('svm', SVC(kernel='linear'))\n",
        "])\n",
        "\n",
        "# Train the SVM model\n",
        "svm_model.fit(X_train, y_train_encoded)\n",
        "\n",
        "# Predictions\n",
        "predictions = svm_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test_encoded, predictions)\n",
        "classification_rep = classification_report(y_test_encoded, predictions)\n",
        "\n",
        "print(f'Accuracy: {accuracy * 100:.2f}%')\n",
        "print('\\nClassification Report:')\n",
        "print(classification_rep)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic Regression\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "import re\n",
        "import nltk\n",
        "\n",
        "# Download NLTK resources\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(data['text'], data['sentiment'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Label encoding for sentiment labels\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(y_train)\n",
        "y_test_encoded = label_encoder.transform(y_test)\n",
        "\n",
        "# Create a TF-IDF vectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "\n",
        "# Transform the text data into TF-IDF features\n",
        "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
        "\n",
        "# Create a logistic regression model\n",
        "logistic_regression_model = LogisticRegression()\n",
        "\n",
        "# Train the logistic regression model\n",
        "logistic_regression_model.fit(X_train_tfidf, y_train_encoded)\n",
        "\n",
        "# Predictions\n",
        "predictions = logistic_regression_model.predict(X_test_tfidf)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test_encoded, predictions)\n",
        "classification_rep = classification_report(y_test_encoded, predictions)\n",
        "\n",
        "print(f'Accuracy: {accuracy * 100:.2f}%')\n",
        "print('\\nClassification Report:')\n",
        "print(classification_rep)"
      ],
      "metadata": {
        "id": "bLE6E3bxznDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Forest\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(data['text'], data['sentiment'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert text data to TF-IDF features\n",
        "vectorizer = TfidfVectorizer(max_features=5000)  # You can adjust the max_features based on your vocabulary size\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = vectorizer.transform(X_test)\n",
        "\n",
        "# Build and train the Random Forest model\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "predictions = rf_model.predict(X_test_tfidf)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "classification_rep = classification_report(y_test, predictions)\n",
        "\n",
        "print(f'Accuracy: {accuracy * 100:.2f}%')\n",
        "print('\\nClassification Report:')\n",
        "print(classification_rep)\n"
      ],
      "metadata": {
        "id": "64IZcPAMzpaN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}